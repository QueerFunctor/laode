\documentclass{ximera}

\input{../preamble.tex}

\title{Eigenvalues of $2\times 2$ Matrices}

\begin{document}
\begin{abstract}
\end{abstract}
\maketitle


\label{S:evchp}


We now discuss how to find eigenvalues
\index{eigenvalue} of $2\times 2$ matrices in a way that does
not depend explicitly on finding eigenvectors.
\index{eigenvector} This direct method will show that
eigenvalues can be complex as well as real.

We begin the discussion with a general square matrix.  Let $A$
be an $n\times n$ matrix.  Recall that $\lambda\in\R$ is an
eigenvalue of $A$ if there is a nonzero vector $v\in\R^n$ for
which
\begin{equation}  \label{eigeneqn}
Av = \lambda v.
\end{equation}
The vector $v$ is called an eigenvector.  We may rewrite
\Ref{eigeneqn} as:
\[
(A-\lambda I_n)v = 0.
\]
Since $v$ is nonzero, it follows that if $\lambda$ is an
eigenvalue of $A$, then the matrix $A-\lambda I_n$ is singular.

Conversely, suppose that $A-\lambda I_n$ is singular for some
real number $\lambda$.  Then Theorem~\ref{invertequiv} of 
Chapter~\ref{chap:matrices} implies that there is a nonzero
vector $v\in\R^n$ such that $(A-\lambda I_n)v = 0$. Hence
\Ref{eigeneqn} holds and $\lambda$ is an eigenvalue of $A$.
So, if we had a direct method for determining when a matrix
is singular, then we would have a method for determining
eigenvalues.

\subsubsection*{Characteristic Polynomials}

Corollary~\ref{C:2x2invert} of Chapter~\ref{chap:matrices}
states that $2\times 2$ matrices are singular precisely when
their determinant is zero.  It follows that $\lambda\in\R$ is
an eigenvalue for the $2\times 2$ matrix $A$ precisely when
\begin{equation} \label{deteqn}
\det(A-\lambda I_2) = 0.
\end{equation}
We can compute \Ref{deteqn} explicitly as follows. Note that
\[
A-\lambda I_2 = \left(\begin{array}{cc} a-\lambda & b \\
c & d-\lambda \end{array} \right).
\]
Therefore
\begin{eqnarray}
\det(A-\lambda I_2) & = & (a-\lambda)(d-\lambda) - bc \nonumber \\
& = & \lambda^2 - (a+d)\lambda + (ad-bc). \label{e:charpoly}
\end{eqnarray}

\begin{Def} \label{charpolyn=2}
The {\em characteristic polynomial\/} of the matrix $A$ is
\[
p_A(\lambda) = \det(A-\lambda I_2).
\]
\end{Def} \index{characteristic polynomial}

For an $n\times n$ matrix $A=(a_{ij})$, define the {\em trace\/}
\index{trace} of $A$ to be the sum of the diagonal elements of $A$;
that is
\begin{equation}  \label{e:tracedef}
{\rm tr}(A) = a_{11} + \cdots + a_{nn}.
\end{equation}
Thus, using \Ref{e:charpoly}, we can rewrite the characteristic
polynomial for $2\times 2$ matrices as
\begin{equation} \label{e:invcharpoly}
p_A(\lambda)=\lambda^2 - {\rm tr}(A)\lambda + \det(A).
\end{equation}

As an example, consider the $2\times 2$ matrix
\begin{equation} \label{e:2x2ex}
A=\mattwo{2}{3}{1}{4}.
\end{equation}
Then
\[
A-\lambda I_2 = \left(\begin{array}{cc} 2-\lambda & 3 \\
1 & 4-\lambda \end{array}\right),
\]
and
\[
p_A(\lambda) = (2-\lambda)(4-\lambda)-3 = \lambda^2-6\lambda+5.
\]
It is now easy to verify \Ref{e:invcharpoly} for \Ref{e:2x2ex}.

\subsubsection*{Eigenvalues}

For $2\times 2$ matrices $A$, $p_A(\lambda)$ is a quadratic
polynomial.  As we have discussed, the real roots of $p_A$ are
real eigenvalues of $A$.  For $2\times 2$ matrices we now 
generalize our first definition of eigenvalues, 
Definition~\ref{D:eigenvalue1}, to include complex eigenvalues, as follows.

\begin{Def}
An {\em eigenvalue\/} of $A$ is a root of the characteristic polynomial $p_A$.
\end{Def} \index{eigenvalue} \index{characteristic polynomial}
Suppose that $\lambda_1$ and $\lambda_2$ are the roots of $p_A$.
It follows that
\begin{equation}  \label{e:charpolyprod}
p_A(\lambda) = (\lambda-\lambda_1)(\lambda-\lambda_2) =
\lambda^2 - (\lambda_1+\lambda_2)\lambda + \lambda_1\lambda_2.
\end{equation}
Equating the two forms of $p_A$ \Ref{e:invcharpoly} and
\Ref{e:charpolyprod} shows that
\begin{eqnarray}
\trace(A) & = & \lambda_1 + \lambda_2 \label{e:treigen}\\
\det(A) & = & \lambda_1\lambda_2. \label{e:deteigen}
\end{eqnarray}
Thus, for $2\times 2$ matrices, the trace is the sum of the
eigenvalues and the determinant is the product of the eigenvalues.
In Chapter~\ref{C:D&E}, Theorems~\ref{T:eigens}(b) and
\ref{T:tracen} we show that these statements are also valid for
$n\times n$ matrices.

Recall that in example \Ref{e:2x2ex} the characteristic polynomial
is
\[
p_A(\lambda) = \lambda^2-6\lambda+5=(\lambda-5)(\lambda-1).
\]
Thus the eigenvalues of $A$ are $\lambda_1=1$ and $\lambda_2=5$
and identities \Ref{e:treigen} and \Ref{e:deteigen} are easily
verified for this example.  

Next, we consider an example with complex eigenvalues and verify that these 
identities are equally valid in this instance.  Let
\[
B = \mattwo{2}{-3}{1}{4}.
\]
The characteristic polynomial is:
\[
p_B(\lambda) = \lambda^2 -6\lambda + 11.
\]
Using the quadratic formula we see that the roots of $p_B$ (that
is, the eigenvalues of $B$) are
\[
\lambda_1 = 3 + i\sqrt{2} \AND \lambda_2 = 3 -i\sqrt{2}.
\]
Again the sum of the eigenvalues is $6$ which equals the trace
of $B$ and the product of the eigenvalues is $11$ which equals
the determinant of $B$.

Since the characteristic polynomial of $2\times 2$ matrices is
always a quadratic polynomial, it follows that $2\times 2$
matrices have precisely two eigenvalues --- including
multiplicity --- and these can be described as follows.  The
{\em discriminant\/}\index{discriminant} of $A$ is:
\begin{equation}  \label{e:discriminant}
D = [\trace(A)]^2 -4\det(A).
\end{equation}
\begin{thm} \label{eigendist}
There are three possibilities for the two eigenvalues of a
$2\times 2$ matrix $A$ that we can describe in terms of the
discriminant:
\begin{itemize}
\item[(i)] The eigenvalues of $A$ are real and distinct ($D>0$).
\item[(ii)] The eigenvalues of $A$ are a complex conjugate pair ($D<0$).
\item[(iii)] The eigenvalues of $A$ are real and equal ($D=0$).
\end{itemize}
\end{thm} \index{eigenvalue}

\begin{proof} We can find the roots of the characteristic polynomial
using the form of $p_A$ given in \Ref{e:invcharpoly} and the
quadratic formula.  The roots are:
\[
\frac{1}{2}\left({\rm tr}(A)\pm \sqrt{[{\rm tr}(A)]^2-4\det(A)}\right)
= \frac{{\rm tr}(A) \pm \sqrt{D}}{2}.
\]
The proof of the theorem now follows.  If $D>0$, then the
eigenvalues of $A$ are real and distinct; if $D<0$, then
eigenvalues are complex conjugates; and if $D=0$, then the
eigenvalues are real and equal.  \end{proof}

\subsection*{Eigenvectors}

The following lemma contains an important observation about eigenvectors:
\begin{lemma} \label{L:eigenexists}
Every eigenvalue $\lambda$ of a $2\times 2$ matrix $A$ has an
eigenvector $v$.  That is, there is a nonzero vector $v\in\C^2$
satisfying
\[
Av = \lambda v.
\]
\end{lemma} \index{eigenvector}


\begin{proof}  When the eigenvalue $\lambda$ is real we know that an
eigenvector $v\in\R^2$ exists.  However, when $\lambda$ is complex,
then we must show that there is a complex eigenvector $v\in\C^2$,
and this we have not yet done.  More precisely, we must show that
if $\lambda$ is a complex root of the characteristic polynomial
$p_A$, then there is a complex vector $v$ such that
\[
(A-\lambda I_2)v = 0.
\]

As we discussed in Section~\ref{S:specialcoeff}, finding $v$ is
equivalent to showing that the complex matrix
\[
A-\lambda I_2 = \left(\begin{array}{cc} a-\lambda & b \\
c & d-\lambda \end{array} \right)
\]
is not row equivalent to the identity matrix.  See
Theorem~\ref{T:complexcoeff} of Chapter~\ref{lineq}.  Since
$a$ is real and $\lambda$ is not, $a-\lambda\neq 0$. A
short calculation shows that $A-\lambda I_2$ is row equivalent to
the matrix
\arraystart
\[
\left(\begin{array}{cc} 1 & \dps\frac{b}{a-\lambda} \\
0 & \dps\frac{p_A(\lambda)}{a-\lambda} \end{array} \right).
\]
\arrayfinish
This matrix is not row equivalent to the identity matrix since
$p_A(\lambda)=0$.  \end{proof}

\subsubsection*{An Example of a Matrix with Real Eigenvectors}

Once we know the eigenvalues of a $2\times 2$ matrix, the associated eigenvectors can be found by direct calculation.  For example, we 
showed previously that the matrix
\[
A=\mattwo{2}{3}{1}{4}.
\]
in \Ref{e:2x2ex} has eigenvalues $\lambda_1=1$ and $\lambda_2=5$.  
With this information we can find the associated eigenvectors.  To find 
an eigenvector associated with the eigenvalue $\lambda_1=1$ compute
\[
A-\lambda_1 I_2 = A-I_2 = \mattwo{1}{3}{1}{3}.
\]
It follows that $v_1=(3,-1)^t$ is an eigenvector since 
\[
(A-I_2)v_1 = 0.
\]
Similarly, to find an eigenvector associated with the eigenvalue 
$\lambda_2=5$ compute
\[
A - \lambda_2 I_2 = A-5I_2 = \mattwo{-3}{3}{1}{-1}.
\]
It follows that $v_2=(1,1)^t$ is an eigenvector since 
\[
(A-5I_2)v_2 = 0.
\]


\subsubsection*{Examples of Matrices with Complex Eigenvectors}
\index{eigenvalue!complex}

Let
\[
A = \mattwo{0}{-1}{1}{0}.
\]
Then $p_A(\lambda)=\lambda^2+1$ and the eigenvalues of $A$ are
$\pm i$.  To find the eigenvector $v\in\C^2$ whose existence is
guaranteed by Lemma~\ref{L:eigenexists}, we need to solve the
complex system of linear equations $Av=iv$.  We can rewrite this
system as:
\[
\mattwo{-i}{-1}{1}{-i}\vectwo{v_1}{v_2} = 0.
\]
A calculation shows that
\begin{equation}  \label{e:eigenv}
v = \vectwo{i}{1}
\end{equation}
is a solution.  Since the coefficients of $A$ are real, we can
take the complex conjugate of the equation $Av=iv$ to obtain
\[
A\overline{v}=-i\overline{v}.
\]
Thus
\[
\overline{v} = \vectwo{-i}{1}
\]
is the eigenvector corresponding to the eigenvalue $-i$.  This
comment is valid for any complex eigenvalue.

More generally, let
\begin{equation}  \label{E:cmplxnf}
A = \mattwo{\sigma}{-\tau}{\tau}{\sigma},
\end{equation}
where $\tau\neq 0$.  Then
\begin{eqnarray*}
p_A(\lambda) & = & \lambda^2 -2\sigma\lambda+\sigma^2+\tau^2 \\
& = & (\lambda-(\sigma+i\tau))(\lambda-(\sigma-i\tau)),
\end{eqnarray*}
and the eigenvalues of $A$ are the complex conjugates
$\sigma\pm i\tau$.  Thus $A$ has no real eigenvectors.  The
complex eigenvectors of $A$ are $v$ and $\overline{v}$ where $v$
is defined in \Ref{e:eigenv}.




\EXER

\TEXER

\begin{exercise} \label{c4.9.2}
For which values of $\lambda$ is the matrix
\[
\left(\begin{array}{cc} 1-\lambda & 4\\  2 & 3-\lambda
\end{array}\right)
\]
{\em not\/} invertible?  {\bf Note:} These values of $\lambda$
are just the eigenvalues of the matrix $\mattwo{1}{4}{2}{3}$.
\end{exercise}

\noindent In Exercises~\ref{c6.4.1a} -- \ref{c6.4.1d} compute the
determinant, trace, and characteristic polynomials for the given 
$2\times 2$ matrix.
\begin{exercise} \label{c6.4.1a}
$\mattwo{1}{4}{0}{-1}$.
\end{exercise}
\begin{exercise} \label{c6.4.1b}
$\mattwo{2}{13}{-1}{5}$.
\end{exercise}
\begin{exercise} \label{c6.4.1c}
$\mattwo{1}{4}{1}{-1}$.
\end{exercise}
\begin{exercise} \label{c6.4.1d}
$\mattwo{4}{10}{2}{5}$.
\end{exercise}

\noindent In Exercises~\ref{c6.4.2a} -- \ref{c6.4.2c} compute the
eigenvalues for the given $2\times 2$ matrix.
\begin{exercise} \label{c6.4.2a}
$\mattwo{1}{2}{0}{-5}$.
\end{exercise}
\begin{exercise} \label{c6.4.2b}
$\mattwo{-3}{2}{1}{0}$.
\end{exercise}
\begin{exercise} \label{c6.4.2c}
$\mattwo{3}{-2}{2}{-1}$.
\end{exercise}

\begin{exercise} \label{c6.4.3}
\begin{itemize}
\item[(a)] Let $A$ and $B$ be $2\times 2$ matrices. Using direct
calculation, show that
\begin{equation}  \label{e:trAB=trBA}
{\rm tr}(AB) = {\rm tr}(BA).
\end{equation}
\item[(b)] Now let $A$ and $B$ be $n\times n$ matrices. Verify
by direct calculation that \Ref{e:trAB=trBA} is still valid.
\end{itemize}
\end{exercise}



\CEXER



\noindent In Exercises~\ref{c7.8.5a} -- \ref{c7.8.5c} use the program
{\sf map} to guess whether the given matrix has real or complex conjugate
eigenvalues.  For each example, write the reasons for your guess.
\begin{exercise} \label{c7.8.5a}
$A=\left(\begin{array}{rr} 0.97 & -0.22\\ 0.22 & 0.97
\end{array}\right)$.
\end{exercise}
\begin{exercise} \label{c7.8.5b}
$B=\left(\begin{array}{rr} 0.97 & 0.22\\ 0.22 & 0.97
\end{array}\right)$.
\end{exercise}
\begin{exercise} \label{c7.8.5c}
$C=\left(\begin{array}{rr} 0.4 & -1.4\\ 1.5 & 0.5
\end{array}\right)$.
\end{exercise}

\noindent In Exercises~\ref{c7.8.6a} -- \ref{c7.8.6b} use the program
{\sf map} to guess one of the eigenvectors of the given matrix.  What is
the corresponding eigenvalue?  Using {\sf map}, can you find a second
eigenvalue and eigenvector?
\begin{exercise} \label{c7.8.6a}
$A=\left(\begin{array}{rr} 2 & 4\\ 2 & 0
\end{array}\right)$.
\end{exercise}
\begin{exercise} \label{c7.8.6b}
$B=\left(\begin{array}{rr} 2 & -1\\ 0.25 & 1
\end{array}\right)$.

\noindent {\bf Hint:} Use the feature {\sf Rescale} in the
{\sf MAP Options}.  Then the length of the vector is rescaled to one
after each use of the command {\sf Map}. In this way you can avoid
overflows in the computations while still being able to see the
directions where the vectors are moved by the matrix mapping.
\end{exercise}

\begin{exercise} \label{c7.8.7}
The \Matlab command {\tt eig}\index{\computer!eig} computes the eigenvalues
of matrices.  Use {\tt eig} to compute the eigenvalues of 
$A = \mattwoc{2.34}{-1.43}{\pi}{e}$.
\end{exercise}



\end{document}
