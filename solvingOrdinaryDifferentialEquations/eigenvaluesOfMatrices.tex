\documentclass{ximera}

\input{../preamble.tex}

\title{Eigenvalues of $2\times 2$ Matrices}

\begin{document}
\begin{abstract}
\end{abstract}
\maketitle


\label{S:evchp}


We now discuss how to find eigenvalues
\index{eigenvalue} of $2\times 2$ matrices in a way that does
not depend explicitly on finding eigenvectors.
\index{eigenvector} This direct method will show that
eigenvalues can be complex as well as real.

We begin the discussion with a general square matrix.  Let $A$
be an $n\times n$ matrix.  Recall that $\lambda\in\R$ is an
eigenvalue of $A$ if there is a nonzero vector $v\in\R^n$ for
which
\begin{equation}  \label{eigeneqn}
Av = \lambda v.
\end{equation}
The vector $v$ is called an eigenvector.  We may rewrite
\eqref{eigeneqn} as:
\[
(A-\lambda I_n)v = 0.
\]
Since $v$ is nonzero, it follows that if $\lambda$ is an
eigenvalue of $A$, then the matrix $A-\lambda I_n$ is singular.

Conversely, suppose that $A-\lambda I_n$ is singular for some
real number $\lambda$.  Then Theorem~\ref{invertequiv} of 
Chapter~\ref{chap:matrices} implies that there is a nonzero
vector $v\in\R^n$ such that $(A-\lambda I_n)v = 0$. Hence
\eqref{eigeneqn} holds and $\lambda$ is an eigenvalue of $A$.
So, if we had a direct method for determining when a matrix
is singular, then we would have a method for determining
eigenvalues.

\subsubsection*{Characteristic Polynomials}

Corollary~\ref{C:2x2invert} of Chapter~\ref{chap:matrices}
states that $2\times 2$ matrices are singular precisely when
their determinant is zero.  It follows that $\lambda\in\R$ is
an eigenvalue for the $2\times 2$ matrix $A$ precisely when
\begin{equation} \label{deteqn}
\det(A-\lambda I_2) = 0.
\end{equation}
We can compute \eqref{deteqn} explicitly as follows. Note that
\[
A-\lambda I_2 = \left(\begin{array}{cc} a-\lambda & b \\
c & d-\lambda \end{array} \right).
\]
Therefore
\begin{eqnarray}
\det(A-\lambda I_2) & = & (a-\lambda)(d-\lambda) - bc \nonumber \\
& = & \lambda^2 - (a+d)\lambda + (ad-bc). \label{e:charpoly}
\end{eqnarray}

\begin{definition} \label{charpolyn=2}
The {\em characteristic polynomial\/} of the matrix $A$ is
\[
p_A(\lambda) = \det(A-\lambda I_2).
\]
\end{definition} \index{characteristic polynomial}

For an $n\times n$ matrix $A=(a_{ij})$, define the {\em trace\/}
\index{trace} of $A$ to be the sum of the diagonal elements of $A$;
that is
\begin{equation}  \label{e:tracedef}
{\rm tr}(A) = a_{11} + \cdots + a_{nn}.
\end{equation}
Thus, using \eqref{e:charpoly}, we can rewrite the characteristic
polynomial for $2\times 2$ matrices as
\begin{equation} \label{e:invcharpoly}
p_A(\lambda)=\lambda^2 - {\rm tr}(A)\lambda + \det(A).
\end{equation}

As an example, consider the $2\times 2$ matrix
\begin{equation} \label{e:2x2ex}
A=\mattwo{2}{3}{1}{4}.
\end{equation}
Then
\[
A-\lambda I_2 = \left(\begin{array}{cc} 2-\lambda & 3 \\
1 & 4-\lambda \end{array}\right),
\]
and
\[
p_A(\lambda) = (2-\lambda)(4-\lambda)-3 = \lambda^2-6\lambda+5.
\]
It is now easy to verify \eqref{e:invcharpoly} for \eqref{e:2x2ex}.

\subsubsection*{Eigenvalues}

For $2\times 2$ matrices $A$, $p_A(\lambda)$ is a quadratic
polynomial.  As we have discussed, the real roots of $p_A$ are
real eigenvalues of $A$.  For $2\times 2$ matrices we now 
generalize our first definition of eigenvalues, 
Definition~\ref{D:eigenvalue1}, to include complex eigenvalues, as follows.

\begin{definition}
An {\em eigenvalue\/} of $A$ is a root of the characteristic polynomial $p_A$.
\end{definition} \index{eigenvalue} \index{characteristic polynomial}
Suppose that $\lambda_1$ and $\lambda_2$ are the roots of $p_A$.
It follows that
\begin{equation}  \label{e:charpolyprod}
p_A(\lambda) = (\lambda-\lambda_1)(\lambda-\lambda_2) =
\lambda^2 - (\lambda_1+\lambda_2)\lambda + \lambda_1\lambda_2.
\end{equation}
Equating the two forms of $p_A$ \eqref{e:invcharpoly} and
\eqref{e:charpolyprod} shows that
\begin{eqnarray}
\trace(A) & = & \lambda_1 + \lambda_2 \label{e:treigen}\\
\det(A) & = & \lambda_1\lambda_2. \label{e:deteigen}
\end{eqnarray}
Thus, for $2\times 2$ matrices, the trace is the sum of the
eigenvalues and the determinant is the product of the eigenvalues.
In Chapter~\ref{C:D&E}, Theorems~\ref{T:eigens}(b) and
\ref{T:tracen} we show that these statements are also valid for
$n\times n$ matrices.

Recall that in example \eqref{e:2x2ex} the characteristic polynomial
is
\[
p_A(\lambda) = \lambda^2-6\lambda+5=(\lambda-5)(\lambda-1).
\]
Thus the eigenvalues of $A$ are $\lambda_1=1$ and $\lambda_2=5$
and identities \eqref{e:treigen} and \eqref{e:deteigen} are easily
verified for this example.  

Next, we consider an example with complex eigenvalues and verify that these 
identities are equally valid in this instance.  Let
\[
B = \mattwo{2}{-3}{1}{4}.
\]
The characteristic polynomial is:
\[
p_B(\lambda) = \lambda^2 -6\lambda + 11.
\]
Using the quadratic formula we see that the roots of $p_B$ (that
is, the eigenvalues of $B$) are
\[
\lambda_1 = 3 + i\sqrt{2} \AND \lambda_2 = 3 -i\sqrt{2}.
\]
Again the sum of the eigenvalues is $6$ which equals the trace
of $B$ and the product of the eigenvalues is $11$ which equals
the determinant of $B$.

Since the characteristic polynomial of $2\times 2$ matrices is
always a quadratic polynomial, it follows that $2\times 2$
matrices have precisely two eigenvalues --- including
multiplicity --- and these can be described as follows.  The
{\em discriminant\/}\index{discriminant} of $A$ is:
\begin{equation}  \label{e:discriminant}
D = [\trace(A)]^2 -4\det(A).
\end{equation}
\begin{theorem} \label{eigendist}
There are three possibilities for the two eigenvalues of a
$2\times 2$ matrix $A$ that we can describe in terms of the
discriminant:
\begin{itemize}
\item[(i)] The eigenvalues of $A$ are real and distinct ($D>0$).
\item[(ii)] The eigenvalues of $A$ are a complex conjugate pair ($D<0$).
\item[(iii)] The eigenvalues of $A$ are real and equal ($D=0$).
\end{itemize}
\end{theorem} \index{eigenvalue}

\begin{proof} We can find the roots of the characteristic polynomial
using the form of $p_A$ given in \eqref{e:invcharpoly} and the
quadratic formula.  The roots are:
\[
\frac{1}{2}\left({\rm tr}(A)\pm \sqrt{[{\rm tr}(A)]^2-4\det(A)}\right)
= \frac{{\rm tr}(A) \pm \sqrt{D}}{2}.
\]
The proof of the theorem now follows.  If $D>0$, then the
eigenvalues of $A$ are real and distinct; if $D<0$, then
eigenvalues are complex conjugates; and if $D=0$, then the
eigenvalues are real and equal.  \end{proof}

\subsection*{Eigenvectors}

The following lemma contains an important observation about eigenvectors:
\begin{lemma} \label{L:eigenexists}
Every eigenvalue $\lambda$ of a $2\times 2$ matrix $A$ has an
eigenvector $v$.  That is, there is a nonzero vector $v\in\C^2$
satisfying
\[
Av = \lambda v.
\]
\end{lemma} \index{eigenvector}


\begin{proof}  When the eigenvalue $\lambda$ is real we know that an
eigenvector $v\in\R^2$ exists.  However, when $\lambda$ is complex,
then we must show that there is a complex eigenvector $v\in\C^2$,
and this we have not yet done.  More precisely, we must show that
if $\lambda$ is a complex root of the characteristic polynomial
$p_A$, then there is a complex vector $v$ such that
\[
(A-\lambda I_2)v = 0.
\]

As we discussed in Section~\ref{S:specialcoeff}, finding $v$ is
equivalent to showing that the complex matrix
\[
A-\lambda I_2 = \left(\begin{array}{cc} a-\lambda & b \\
c & d-\lambda \end{array} \right)
\]
is not row equivalent to the identity matrix.  See
Theorem~\ref{T:complexcoeff} of Chapter~\ref{lineq}.  Since
$a$ is real and $\lambda$ is not, $a-\lambda\neq 0$. A
short calculation shows that $A-\lambda I_2$ is row equivalent to
the matrix
\arraystart
\[
\left(\begin{array}{cc} 1 & \dps\frac{b}{a-\lambda} \\
0 & \dps\frac{p_A(\lambda)}{a-\lambda} \end{array} \right).
\]
\arrayfinish
This matrix is not row equivalent to the identity matrix since
$p_A(\lambda)=0$.  \end{proof}

\subsubsection*{An Example of a Matrix with Real Eigenvectors}

Once we know the eigenvalues of a $2\times 2$ matrix, the associated eigenvectors can be found by direct calculation.  For example, we 
showed previously that the matrix
\[
A=\mattwo{2}{3}{1}{4}.
\]
in \eqref{e:2x2ex} has eigenvalues $\lambda_1=1$ and $\lambda_2=5$.  
With this information we can find the associated eigenvectors.  To find 
an eigenvector associated with the eigenvalue $\lambda_1=1$ compute
\[
A-\lambda_1 I_2 = A-I_2 = \mattwo{1}{3}{1}{3}.
\]
It follows that $v_1=(3,-1)^t$ is an eigenvector since 
\[
(A-I_2)v_1 = 0.
\]
Similarly, to find an eigenvector associated with the eigenvalue 
$\lambda_2=5$ compute
\[
A - \lambda_2 I_2 = A-5I_2 = \mattwo{-3}{3}{1}{-1}.
\]
It follows that $v_2=(1,1)^t$ is an eigenvector since 
\[
(A-5I_2)v_2 = 0.
\]


\subsubsection*{Examples of Matrices with Complex Eigenvectors}
\index{eigenvalue!complex}

Let
\[
A = \mattwo{0}{-1}{1}{0}.
\]
Then $p_A(\lambda)=\lambda^2+1$ and the eigenvalues of $A$ are
$\pm i$.  To find the eigenvector $v\in\C^2$ whose existence is
guaranteed by Lemma~\ref{L:eigenexists}, we need to solve the
complex system of linear equations $Av=iv$.  We can rewrite this
system as:
\[
\mattwo{-i}{-1}{1}{-i}\vectwo{v_1}{v_2} = 0.
\]
A calculation shows that
\begin{equation}  \label{e:eigenv}
v = \vectwo{i}{1}
\end{equation}
is a solution.  Since the coefficients of $A$ are real, we can
take the complex conjugate of the equation $Av=iv$ to obtain
\[
A\overline{v}=-i\overline{v}.
\]
Thus
\[
\overline{v} = \vectwo{-i}{1}
\]
is the eigenvector corresponding to the eigenvalue $-i$.  This
comment is valid for any complex eigenvalue.

More generally, let
\begin{equation}  \label{E:cmplxnf}
A = \mattwo{\sigma}{-\tau}{\tau}{\sigma},
\end{equation}
where $\tau\neq 0$.  Then
\begin{eqnarray*}
p_A(\lambda) & = & \lambda^2 -2\sigma\lambda+\sigma^2+\tau^2 \\
& = & (\lambda-(\sigma+i\tau))(\lambda-(\sigma-i\tau)),
\end{eqnarray*}
and the eigenvalues of $A$ are the complex conjugates
$\sigma\pm i\tau$.  Thus $A$ has no real eigenvectors.  The
complex eigenvectors of $A$ are $v$ and $\overline{v}$ where $v$
is defined in \eqref{e:eigenv}.




\EXER

\includeexercises



\end{document}
