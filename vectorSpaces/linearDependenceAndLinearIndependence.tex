\documentclass{ximera}

\input{../preamble.tex}

\title{Linear Dependence and Linear Independence}

\begin{document}
\begin{abstract}
\end{abstract}
\maketitle

 \label{S:5.4}

An important question in linear algebra concerns finding spanning
sets for subspaces having the smallest
number of vectors. Let $w_1,\ldots,w_k$ be vectors in a vector
space $V$ and let $W=\Span\{w_1,\ldots,w_k\}$.  \index{span}
Suppose that $W$ is generated by a subset of these $k$ vectors.
Indeed, suppose that the $k^{th}$ vector is redundant in the
sense that $W=\Span\{w_1,\ldots,w_{k-1}\}$.  Since $w_k\in W$,
this is possible only if $w_k$ is a linear combination of the
$k-1$ vectors $w_1,\ldots,w_{k-1}$; that is, only if
\begin{equation}  \label{e:depend}
w_k = r_1w_1 + \cdots + r_{k-1}w_{k-1}.
\end{equation}
\begin{definition}  \label{lineardependence}
Let $w_1,\ldots,w_k$ be vectors in the vector space $V$.  The set
$\{w_1,\ldots,w_k\}$ is {\em linearly dependent\/} if one of the vectors
$w_j$ can be written as a linear combination of the remaining $k-1$ vectors.
\end{definition} \index{linearly!dependent} \index{linear!combination}
Note that when $k=1$, the phrase `$\{w_1\}$ is linearly dependent'
means that $w_1=0$.

If we set $r_k=-1$, then we may rewrite \eqref{e:depend} as
\[
r_1w_1 + \cdots + r_{k-1}w_{k-1} + r_k w_k =0.
\]
It follows that:
\begin{lemma}  \label{L:lindep}
The set of vectors $\{w_1,\ldots,w_k\}$ is linearly dependent if and
only if there exist scalars $r_1,\ldots,r_k$ such that
\begin{itemize}
\item[(a)]   at least one of the $r_j$ is nonzero, and
\item[(b)]   $r_1w_1 + \cdots + r_k w_k =0.$
\end{itemize}
\end{lemma}

For example, the vectors $w_1=(2,4,7)$, $w_2=(5,1,-1)$, and
$w_3=(1,-7,-15)$ are linearly dependent since $2w_1-w_2+w_3=0$.

\begin{definition}  \label{linearindependence}
A set of $k$ vectors $\{w_1,\ldots,w_k\}$ is {\em linearly
independent\/} if none of the $k$ vectors can be written as a
linear combination of the other $k-1$ vectors.
\end{definition} \index{linearly!independent}

Since linear independence means {\em not\/} linearly dependent,
Lemma~\ref{L:lindep} can be rewritten as:
\begin{lemma}  \label{L:linindep}
The set of vectors $\{w_1,\ldots,w_k\}$ is linearly independent if and
only if whenever
\[
r_1w_1 + \cdots + r_kw_k = 0,
\]
it follows that
\[
r_1 = r_2 = \cdots = r_k = 0.
\]
\end{lemma}

Let $e_j$ be the vector in $\R^n$ whose $j^{th}$ component is $1$
and all of whose other components are $0$. The set of vectors
$e_1,\ldots,e_n$ is the simplest example of a set of linearly
independent vectors in $\R^n$.  We use Lemma~\ref{L:linindep} to
verify independence by supposing that
\[
r_1e_1 + \cdots + r_ne_n = 0.
\]
A calculation shows that
\[
0 = r_1e_1 + \cdots + r_ne_n = (r_1,\ldots,r_n).
\]
It follows that each $r_j$ equals $0$, and the vectors
$e_1,\ldots,e_n$ are linearly independent.


\subsection*{Deciding Linear Dependence and Linear Independence}
\index{linearly!dependent}

Deciding whether a set of $k$ vectors in $\R^n$ is linearly
dependent or linearly independent is equivalent to solving a
system of linear equations.  Let $w_1,\ldots,w_k$ be vectors
in $\R^n$, and view these vectors as column vectors. Let
\begin{equation}  \label{E:Ank}
A=(w_1|\cdots|w_k)
\end{equation}
be the $n\times k$ matrix whose columns are the vectors $w_j$.
Then a vector
\[
R = \vect{r}{k}
\]
is a solution to the system of equations $AR=0$ precisely when
\begin{equation}
r_1w_1 + \cdots + r_kw_k = 0.
\end{equation}
If there is a nonzero solution $R$ to $AR=0$, then the vectors
$\{w_1,\ldots,w_k\}$ are linearly dependent; if the only solution
to $AR=0$ is $R=0$, then the vectors are linearly independent.

The preceding discussion is summarized by:
\begin{lemma}
The vectors $w_1,\ldots,w_k$ in $\R^n$ are linearly dependent if the
null space of the $n\times k$ matrix $A$ defined in \eqref{E:Ank} is
nonzero and linearly independent if the null space of $A$ is zero.
\end{lemma} \index{linearly!dependent}\index{linearly!independent}
\index{null space}


\subsubsection*{A Simple Example of Linear Independence with Two Vectors}

The two vectors
\[
w_1 = \left(\begin{array}{r} 2 \\ -8\\ 1\\ 0 \end{array}\right)
\AND
w_2 = \left(\begin{array}{r} 1 \\ -2\\ 0\\ 1 \end{array}\right)
\]
are linearly independent.  To see this suppose that
$r_1 w_1 + r_2 w_2 = 0$.  Using the components of $w_1$ and $w_2$
this equality is equivalent to the system of four equations
\[
2r_1 + r_2 = 0,\quad -8r_1 - 2r_2 = 0,\quad r_1 = 0, \AND r_2 = 0.
\]
In particular, $r_1 = r_2 = 0$; hence $w_1$ and $w_2$ are
linearly independent.


\subsubsection*{Using \Matlab to Decide Linear Dependence}

Suppose that we want to determine whether or not the vectors
\begin{matlabEquation}\label{MATLAB:66}
w_1 = \left(\begin{array}{r} 1 \\ 2 \\ -1 \\ 3 \\ 5 \end{array}\right)
\quad
w_2 = \left(\begin{array}{r} -1 \\ 1 \\ 4 \\ -2 \\ 0 \end{array}\right)
\quad
w_3 = \left(\begin{array}{r} 1 \\ 1 \\ -1 \\ 3 \\ 12 \end{array}\right)
\quad
w_4 = \left(\begin{array}{r} 0 \\ 4 \\ 3 \\ 1 \\ -2 \end{array}\right)
\end{matlabEquation}%
are linearly dependent.  After typing {\tt e5\_4\_4} in \Matlabp, form
the $5\times 4$ matrix $A$ by typing
\begin{verbatim}
A = [w1 w2 w3 w4]
\end{verbatim}
Determine whether there is a nonzero solution to $AR=0$ by typing
\begin{verbatim}
null(A)
\end{verbatim} \index{\computer!null}
The response from \Matlab is
\begin{verbatim}
ans =
   -0.7559
   -0.3780
    0.3780
    0.3780
\end{verbatim}
showing that there is a nonzero solution to $AR=0$ and the vectors
$w_j$ are linearly dependent.  Indeed, this solution for $R$ shows
that we can solve for $w_1$ in terms of $w_2,w_3,w_4$.
We can now ask whether or not $w_2,w_3,w_4$ are linearly dependent.
To answer this question form the matrix
\begin{verbatim}
B = [w2 w3 w4]
\end{verbatim}
and type {\tt null(B)} to obtain
\begin{verbatim}
ans =
   Empty matrix: 3-by-0
\end{verbatim}
showing that the only solution to $BR=0$ is the zero solution $R=0$.
Thus, $w_2,w_3,w_4$ are linearly independent.  For these particular
vectors, any three of the four are linearly independent.

\EXER

\TEXER

\begin{exercise} \label{c5.4.1}
Let $w$ be a vector in the vector space $V$.  Show that the sets of vectors
$\{w,0\}$ and $\{w,-w\}$ are linearly dependent.

\begin{solution}

To show that the set of vectors $\{w_1,w_2\}$ is linearly dependent,
show that there exist nonzero $a$ and $b$ such that
$aw_1 + bw_2 = 0$.  For the set $\{w,0\}$, if $a = 0$ and $b = 1$,
then $0w + 1(0) = 0$, so the set is linearly dependent.  For the
set $\{w,-w\}$, if $a = 1$ and $b = 1$, then
$w - w = 0$, so the set is linearly dependent.

\end{solution}
\end{exercise}

\begin{exercise} \label{c5.4.2}
For which values of $b$ are the vectors $(1,b)$ and $(3,-1)$
linearly independent?

\begin{solution}

\ans The set is linearly independent if $b \neq -\frac{1}{3}$.

\soln Note that a set of two vectors is linearly dependent if one is
a multiple of the other.  So this set is dependent for any values of
$b$ at which
\[
(3,-1) = \alpha(1,b).
\]
When equality holds $\alpha = 3$.  Therefore, $b = -\frac{1}{3}$.  

\end{solution}
\end{exercise}

\begin{exercise} \label{c5.4.3}
Let
\[
u_1=(1,-1,1) \quad u_2=(2,1,-2) \quad u_3 = (10,2,-6).
\]
Is the set $\{u_1,u_2,u_3\}$ linearly dependent or linearly independent?

\begin{solution}

\ans The set is linearly dependent.

\soln Let $A$ be the matrix whose columns are $u_1$, $u_2$, and $u_3$. 
The set $\{u_1,u_2,u_3\}$ is linearly dependent if there exists
a nonzero vector $r = (r_1,r_2,r_3)$ such that $r_1u_1 + r_2u_2 +
r_3u_3 = 0$, that is, if the homogeneous system $Ar = 0$ has a
nonzero solution.  Row reduce:
\[
\matthree{1}{2}{10}{-1}{1}{2}{1}{-2}{-6} \longrightarrow
\matthree{1}{0}{2}{0}{1}{4}{0}{0}{0}.
\]
So, $Ar = 0$ when $r = r_3(-2,-4,1)$.
The value of $r$ is nonzero for $r_3 \neq 0$, so the set is indeed
linearly dependent.
As an example, let $r_3 = 1$.  Then,
\[
-4u_1 - 2u_2 + u_3 = -2(1,-1,1) - 4(2,1,-2) + (10,2,-6) =
(0,0,0) = 0.
\]

\end{solution}
\end{exercise}


\begin{exercise} \label{c5.4.4}
For which values of $b$ are the vectors $(1,b,2b)$ and $(2,1,4)$
linearly independent?

\begin{solution}

\ans The vectors $(1,b,2b)$ and $(2,1,4)$ are linearly independent
for any value of $b$.

\soln Two vectors are linearly independent unless one is a multiple
of the other; in this case, unless
\[
(1,b,2b) = \alpha(2,1,4).
\]
Equality holds if $2\alpha = 1$, $\alpha = b$, and $4\alpha = 2b$.
Therefore, $\alpha = \frac{1}{2}$, $b = \frac{1}{2}$ and $b = 1$,
which is inconsistent, so the vectors are linearly independent.

\end{solution}
\end{exercise}

\begin{exercise} \label{c5.4.5}
Show that the polynomials $p_1(t) = 2+t$, $p_2(t) = 1+t^2$, and
$p_3(t) = t-t^2$ are linearly independent vectors in the vector
space $\CCone$.

\begin{solution}

\ans The polynomials $p_1(t) = 2 + t$, $p_2(t) = 1 + t^2$, and $p_3(t) =
t - t^2$ are linearly independent in $\CCone$.  

\soln We can determine this
by noting that the polynomials are linearly dependent if there exists
a nonzero vector $r = (r_1,r_2,r_3)$ such that $r_1p_1 + r_2p_2 +
r_3p_3 = 0$.  It is convenient to represent each polynomial as a
vector $(a,b,c) = p(t) = a + bt + ct^2$.  Thus, $p_1(t) = (2,1,0)$, 
$p_2(t) = (1,0,1)$, and $p_3(t) = (0,1,-1)$.  Solve the homogeneous
system $Ar = 0$, where $A$ is the matrix whose columns are $p_1$,
$p_2$, and $p_3$, by row reduction.
\[ \matthree{2}{1}{0}{1}{0}{1}{0}{1}{-1} \longrightarrow
\matthree{1}{0}{0}{0}{1}{0}{0}{0}{1}. \]
Therefore, there are no nonzero values of $r$ for which $r_1p_1 + 
r_2p_2 + r_3p_3 = 0$, and the polynomials are linearly independent.


\end{solution}
\end{exercise}

\begin{exercise} \label{c5.4.6}
Show that the functions $f_1(t) = \sin t$, $f_2(t)=\cos t$, and
$f_3(t)=\cos\left(t+\frac{\pi}{3}\right)$ are linearly dependent
vectors in $\CCone$.

\begin{solution}

The three functions are linearly dependent vectors in $\CCone$ since
there exists a nonzero vector $r = (r_1,r_2,r_3)$ such that
$r_1f_1(t) + r_2f_2(t) + r_3f_3(t) = 0$.  We can find this vector $r$
using trigonometric identities:
\[ f_3(t) = \cos\left(t + \frac{\pi}{3}\right) =
\cos\left(\frac{\pi}{3}\right)\cos t + \sin\left(\frac{\pi}{3}\right)\sin t
= \frac{1}{2}\cos t - \frac{\sqrt{3}}{2}\sin t =
\frac{1}{2}f_1(t) - \frac{\sqrt{3}}{2}f_2(t). \]
That is, $\frac{1}{2}f_1(t) + \frac{\sqrt{3}}{2}f_2(t) - f_3(t) = 0$.

\end{solution}
\end{exercise}

\begin{exercise} \label{c5.4.7}
Suppose that the three vectors $u_1,u_2,u_3\in\R^n$ are linearly
independent.  Show that the set
\[
\{u_1+u_2, u_2+u_3,u_3+u_1\}
\]
is also linearly independent.

\begin{solution}

To show that the vectors $u_1 + u_2$, $u_2 + u_3$ and $u_3 + u_1$
are linearly independent, we assume that there exist scalars $r_1$,
$r_2$, $r_3$ such that
\[ r_1(u_1 + u_2) + r_2(u_2 + u_3) + r_3(u_3 + u_1) = 0. \]
We then prove that $r_1 = r_2 = r_3 = 0$, as follows.
Use distribution to obtain
\[ (r_1 + r_3)u_1 + (r_1 + r_2)u_2 + (r_2 + r_3)u_3 = 0. \]
Since the set $\{u_1,u_2,u_3\}$ is linearly independent,
\[ \begin{array}{rrrrrcl}
r_1 & & & + & r_3 & = & 0 \\
r_1 & + & r_2 & & & = & 0 \\
& & r_2 & + & r_3 & = & 0. \end{array} \]
Solving this system yields $r_1 = r_2 = r_3 = 0$,
so the set $\{u_1 + u_2,u_2 + u_3,u_3 + u_1\}$ is linearly
independent.

\end{solution}
\end{exercise}

\CEXER

\noindent In Exercises~\ref{c5.4.8a} -- \ref{c5.4.8c}, determine whether
the given sets of vectors are linearly independent or linearly dependent.
\begin{exercise} \label{c5.4.8a}
\begin{matlabEquation}\label{MATLAB:67}
v_1 = (2,1,3,4) \quad v_2 = (-4,2,3,1) \quad v_3 = (2,9,21,22)
\end{matlabEquation}

\begin{solution}
\ans The set $\{v_1,v_2,v_3\}$ is linearly dependent.

\soln The set is linearly dependent if there exist scalars $r_1$, $r_2$,
and $r_3$ such that $r_1v_1 + r_2v_2 + r_3v_3 = 0$.  Create a matrix
{\tt A} whose columns are $v_1$, $v_2$ and $v_3$.  Then row reduce
{\tt A} to solve the homogeneous system $Ar = 0$.  Specifically, row
reducing the matrix {\tt A = [v1 v2 v3]} yields
\begin{verbatim}
ans =
     1     0     5
     0     1     2
     0     0     0
     0     0     0
\end{verbatim}
So $-5v_1 - 2v_2 + v_3 = 0$.

\end{solution}
\end{exercise}
\begin{exercise} \label{c5.4.8b}
\begin{matlabEquation}\label{MATLAB:68}
w_1 = (1,2,3)\quad w_2 = (2,1,5) \quad w_3 = (-1,2,-4)
\quad w_4 = (0,2,-1)
\end{matlabEquation}

\begin{solution}
\ans The set $\{w_1,w_2,w_3,w_4\}$ is linearly dependent.

\soln Create the matrix {\tt A} associated to the set
$\{w_1,w_2,w_3,w_4\}$, and row reduce to solve for
$r = (r_1,r_2,r_3,r_4)$, obtaining
\begin{verbatim}
ans =
    1.0000         0         0    0.1429
         0    1.0000         0    0.2857
         0         0    1.0000    0.7143
\end{verbatim}
Therefore, $-0.1429w_1 - 0.2857w_2 - 0.7143w_3 + w_4 = 0$.

\end{solution}
\end{exercise}
\begin{exercise} \label{c5.4.8c}
\begin{matlabEquation}\label{MATLAB:69}
x_1 = (3,4,1,2,5) \quad x_2 = (-1,0,3,-2,1)\quad x_3 = (2,4,-3,0,2)
\end{matlabEquation}

\begin{solution}
\ans The set $\{x_1,x_2,x_3\}$ is linearly independent.

\soln The matrix {\tt A} associated to the set $\{x_1,x_2,x_3\}$ row
reduces to
\begin{verbatim}
ans =
     1     0     0
     0     1     0
     0     0     1
     0     0     0
     0     0     0
\end{verbatim}
In this case, there are no nonzero solutions to
$r_1x_1 + r_2x_2 + r_3x_3 = 0$.
 
\end{solution}
\end{exercise}

\begin{exercise} \label{c5.4.9}
Perform the following experiments.
\begin{itemize}
\item[(a)]   Use \Matlab to choose randomly three column vectors in
$\R^3$.  The \Matlab commands to choose these vectors are:
\begin{verbatim}
y1 = rand(3,1)
y2 = rand(3,1)
y3 = rand(3,1)
\end{verbatim}\index{\computer!rand}
Use the methods of this section to determine whether these vectors
are linearly independent or linearly dependent.
\item[(b)]  Now perform this exercise five times and record the number
of times a linearly independent set of vectors is chosen and the
number of times a linearly dependent set is chosen.
\item[(c)]  Repeat the experiment in (b) --- but this time randomly
choose four vectors in $\R^3$ to be in your set.
\end{itemize}

\begin{solution}

(a) The set of commands to perform this experiment is:
\begin{verbatim}
y1 = rand(3,1);
y2 = rand(3,1);
y3 = rand(3,1);
A = [y1 y2 y3];
rref(A)
\end{verbatim}
If the resulting matrix is $I_3$, then the set is linearly
independent.

(b) The most likely outcome is that all five trials result in
linearly independent sets.

(c) Every trial yields a linearly dependent set of vectors.



\end{solution}
\end{exercise}

\end{document}
