\documentclass{ximera}

\input{../preamble.tex}

\title{Qualitative Theory Near Equilibria}

\begin{document}
\begin{abstract}
\end{abstract}
\maketitle


\label{S:QT}


In this section we discuss asymptotic stability and hyperbolicity for 
linear systems of differential equations.  We show, in general, that 
each linear constant coefficient system divides coordinates into three
groups: stable, center, and unstable.   Then, in analogy with the 
planar case, we discuss how solutions to nonlinear autonomous systems 
look very much like solutions to linear differential equations, at least
in a neighborhood of a hyperbolic equilibrium.


\subsection*{Asymptotic Stability}
\index{stability!asymptotic}


Consider the linear system of ODEs $\dot{X}=AX$.  In the case $n=2$ we showed 
that the origin is an asymptotically stable equilibrium precisely when the 
eigenvalues of $A$ have negative real part.  In this subsection we show that the 
same result holds for general $n$. 
\begin{definition}  \label{D:linstab}
The origin is a {\em linearly stable\/} equilibrium for the system 
of differential equations $\dot{X}=AX$ if the $n$ eigenvalues of $A$ 
all have negative real part.  
\end{definition}\index{stability!linear}
Using this definition we have:
\begin{theorem}  \label{T:linstab}
The origin is an asymptotically stable equilibrium for the system of 
differential equations $\dot{X}=AX$ if and only if the origin is linearly stable.
\end{theorem}

\begin{proof} The proof of this theorem follows directly from Lemma~\ref{R:pdeg}.
Each coordinate function of each solution of $\dot{X}=AX$ is a linear 
combination of functions of the form $t^je^{\lambda t}$ where $\lambda$ is 
a real eigenvalue of $A$ and $t^je^{\sigma t}\cos(\tau t)$ and 
$t^je^{\sigma t}\sin(\tau t)$ where $\lambda=\sigma\pm i\tau$ is a complex
eigenvalue of $A$.  Observe that if $\lambda < 0$, then
\[
\lim_{t\to\infty}t^ke^{\lambda t} = 0,
\]
since exponentials decay\index{exponential!decay} to zero faster than 
polynomials grow to infinity.  A similar argument holds when the multiple 
eigenvalue is complex since 
\[
\lim_{t\to\infty}t^ke^{\sigma t}\cos(\tau t) = 0 = 
\lim_{t\to\infty}t^ke^{\sigma t}\sin(\tau t),
\]
when $\sigma < 0$.  \end{proof}

\subsection*{Stable, Unstable and Center Coordinates}

Recall from Chapter~\ref{Chap:PlanarQ} (Theorem~\ref{T:matrixcoord}) that 
two matrices are similar 
precisely when there is a linear change of 
coordinates\index{change of coordinates} that transforms
one matrix into the other.  Thus, when we assume that a matrix $A$ is in 
Jordan normal form\index{Jordan normal form} in the system of differential 
equations $\dot{X}=AX$, 
we are just assuming that we have made a preliminary change of coordinates
to put that matrix in normal form. 

We can always group the eigenvalues of a matrix into three classes: those 
that have negative real part\index{eigenvalue!with negative real part}, 
those that have positive real part\index{eigenvalue!with positive real part}, 
and those that have zero real part\index{eigenvalue!with zero real part}; and 
we can always arrange the Jordan normal form so 
that 
\begin{itemize}
\item[(i)] blocks corresponding to eigenvalues with negative real part come first,
\item[(ii)] blocks corresponding to eigenvalues with positive real part come 
next, and
\item[(iii)] blocks corresponding to eigenvalues with zero real part come last.
\end{itemize}
As a consequence of this discussion we have proved:
\begin{proposition}  \label{P:SUC}
Every $n\times n$ matrix $B$ is similar\index{similar} to a 
block diagonal $n\times n$ matrix\index{matrix!block diagonal}
\begin{equation} \label{e:SUC}
A = \left(\begin{array}{ccc} S & 0 & 0 \\ 0 & U & 0\\ 0 & 0 & C \end{array}
\right),
\end{equation}
where
\begin{itemize}
\item[(a)]	$S$ is a Jordan normal form\index{Jordan normal form}
$k_s\times k_s$ matrix all of whose eigenvalues have negative real part;
\item[(b)]	$U$ is a Jordan normal form $k_u\times k_u$ matrix all
of whose eigenvalues have positive real part; and
\item[(c)]	$C$ is a Jordan normal form $k_c\times k_c$ matrix all
of whose eigenvalues have zero real part;
\end{itemize}
and $k_s+k_u+k_c=n$.
\end{proposition}

Using Proposition~\ref{P:SUC}, we can give a qualitative description of 
every constant coefficient linear system of differential equations.
\begin{theorem}  \label{T:SUC}
Let $A$ be a Jordan normal form matrix in the block diagonal form \eqref{e:SUC}.
Let $X=(x,y,z)\in\R^n$ where $x\in\R^{k_s}$, $y\in\R^{k_u}$ and $z\in\R^{k_c}$.
Then every solution to the differential equation $\dot{X}=AX$ has the form
\[
X(t) = (x(t), y(t),z(t)),
\]
where
\begin{itemize}
\item[(a)]  $x(t)$ decays to zero exponentially fast in 
	forward time and grows to 
	infinity exponentially fast in backward time;
\item[(b)]  $y(t)$ grows to infinity exponentially fast in forward time and 
	decays to zero exponentially fast in backward time; and
\item[(c)]  $z(t)$ can be either bounded or grow or decay. 
\end{itemize}
Moreover, if the Jordan blocks\index{Jordan block} of $C$ are all trivial
(that is, $1\times 1$ zero blocks or $2\times 2$ blocks with complex
conjugate purely imaginary eigenvalues), then $z(t)$ will remain bounded in 
both forward and backward time. 
\end{theorem}

\begin{proof}  The block diagonal form of $A$ decouples the differential equation 
into three subsystems:
\begin{eqnarray*}
\dot{x} & = & Sx \\
\dot{y} & = & Uy \\
\dot{z} & = & Cz.
\end{eqnarray*}  
Since the eigenvalues of $S$ all have negative real part, Theorem~\ref{T:linstab} proves (a).  Since the eigenvalues of $U$ all have 
positive real part, we can run time backwards and obtain the differential 
equation $\dot{y}=-Uy$, where all of the eigenvalues of $-U$ have negative 
real part.  Again, we can use Theorem~\ref{T:linstab} to prove (b).  There 
is nothing to prove in part (c).  However, to prove the last statement, observe
that if the Jordan blocks in $C$ are trivial, then the blocks are either
$1\times 1$ zero blocks or $2\times 2$ blocks $\mattwo{0}{-\tau}{\tau}{0}$.
Solutions to the subblock equations are either equilibria (in the case of a
$1\times 1$ block) or circles (in the case of the $2\times 2$ block).  The
result follows, since the superposition of bounded solutions is bounded. \end{proof}

\begin{definition}
The $x$ coordinates in Theorem~\ref{T:SUC} are the {\em stable\/} coordinates,
the $y$ coordinates are the {\em unstable\/} coordinates, and the $z$ 
coordinates are the {\em center\/} coordinates.
\end{definition}\index{coordinates!stable} \index{coordinates!unstable}
\index{coordinates!center}

Theorem~\ref{T:SUC} implies that for each linear constant coefficient system
of $n$ equations, we can group coordinates of $\R^n$ into stable, unstable,
and center coordinates for that differential equation.  Moreover, we just 
need to know the eigenvalues of the coefficient matrix to make this grouping.


\subsection*{Linearizations near Hyperbolic Equilibria}

Consider the autonomous\index{autonomous} system of differential equations 
\begin{equation} \label{e:eqnn}
\frac{dX}{dt} = f(X),
\end{equation}
where $X\in\R^n$ and $f:\R^n\to\R^n$.  We restate here for higher dimensional 
systems of 
differential equations some of the ideas and terminology that we introduced
previously for planar systems.  The point $X_0\in\R^n$ is an equilibrium 
\index{equilibrium} or steady-state solution\index{steady-state solution} 
if $f(X_0)=0$.  As we have seen, 
$X_0=0$ is an equilibrium of any linear system where $f(X)=AX$ for some 
$n\times n$ matrix $A$. 

Suppose that $X_0$ is an equilibrium for \eqref{e:eqnn}.  Let 
\[
f(X) = (f_1(X),\ldots,f_n(X))
\]
define the coordinate functions of $f$ as a function of $X=(x_1,\ldots,x_n)$.
Recall that the {\em Jacobian matrix\/}\index{matrix!Jacobian}
at $X_0$ is the $n\times n$ matrix of partial 
derivatives of $f$ and is denoted by $(df)_{X_0}$. \index{linearization} 
\index{matrix!Jacobian}  More precisely, 
\arraystart
\[
(df)_{X_0} = \left(\begin{array}{ccc}
\dps\frac{\partial f_1}{\partial x_1}(X_0) & \cdots & 
\dps\frac{\partial f_1}{\partial x_n}(X_0) \\ \vdots &  & \vdots \\
\dps\frac{\partial f_n}{\partial x_1}(X_0) & \cdots & 
\dps\frac{\partial f_n}{\partial x_n}(X_0) \end{array}\right).
\]
\arrayfinish
An equilibrium $X_0$ of \eqref{e:eqnn} is {\em hyperbolic\/} if the $n$
eigenvalues of $(df)_{X_0}$ all have nonzero real part. We now state 
the analog of Theorem~\ref{T:linearization} of Chapter~\ref{C:NPS}.
\index{hyperbolic}\index{equilibrium!hyperbolic}

\begin{theorem}  \label{T:nlinearization}
Suppose that the system of differential equations \eqref{e:eqnn} has a 
hyperbolic equilibrium at $X_0$.  Then, on a sufficiently small neighborhood 
of $X_0$, the phase space for \eqref{e:eqnn} is the {\em same\/} as the phase 
space of the system of linear differential equations
\begin{equation}  \label{e:nlinearizedeqn}
\frac{dX}{dt} = (df)_{X_0}X.
\end{equation}
\end{theorem} 

As before, it is difficult to define precisely what we mean by the word
{\em same\/}. Roughly speaking, {\em same\/} means that near $X_0$ there 
is a nonlinear change of coordinates\index{change of coordinates!nonlinear}
that transforms the nonlinear equation into the linear one.

\subsubsection*{Asymptotically Stable Equilibria in Nonlinear Systems}
\index{equilibrium!asymptotically stable}

We illustrate this theorem and consider the linear system 
$\dot{X}=AX$ where $A$ is given by
\begin{matlabEquation}  \label{eq:fexam4}
A = 
\left(\begin{array}{rrrr}
   -0.1 &  0.1 & -0.2 &  0.1\\
   -0.8 & -0.5 &  1.9 &    0\\
    2.4 & -3.9 & -0.7 &  0.1\\
    0.3 &  0.1 & -0.2 & -0.3
\end{array}\right)
\end{matlabEquation}
We can enter $A$ into \Matlab and compute the eigenvalues of $A$ by typing 
\begin{verbatim}
e12_2_4
eig(A)
\end{verbatim}\index{\computer!eig}
and we obtain
\begin{verbatim}
ans =
  -0.5725+ 2.8194i
  -0.5725- 2.8194i
  -0.0550         
  -0.4000         
\end{verbatim}
In particular, all eigenvalues of $A$ have negative real parts, and 
Theorem~\ref{T:linstab} implies that the origin is an asymptotically 
stable equilibrium\index{equilibrium!asymptotically stable}.

Theorem~\ref{T:nlinearization} implies that the origin remains
asymptotically stable for any system of differential equations
\begin{equation} \label{e:fnonlin}
\dot{X} = AX + N(X),
\end{equation}
where $N(X)$ consists only of higher order terms.  For example, suppose
\begin{equation}  \label{E:fnonlin1}
N(X) = \left(\begin{array}{c} 2x_1^2-x_1x_2 \\ -x_4^3 \\  -x_3^2 \\ x_4x_1
\end{array} \right).
\end{equation}
Then the Jacobian matrix of the right hand side in \eqref{e:fnonlin} at $X_0 = 0$ 
is given by $A$ and Theorem~\ref{T:nlinearization} guarantees that solutions to 
the nonlinear equation \eqref{e:fnonlin} that have an initial condition near 
enough to the origin will tend towards the origin in forward time.  It would be 
nice to test the consequences of this theorem numerically, but until now we
have not discussed how to integrate solutions to differential equations in
more than two dimensions.  We will do this in Section~\ref{S:ode45HD} using a 
three dimensional equation. 

\subsubsection*{Saddles, Sources and Sinks in Higher Dimensions}

Suppose that one eigenvalue $\lambda$ of the $n\times n$ matrix $A$ has 
positive real part.  Then {\em almost all\/} solutions to the linear system 
$\dot{X}=AX$ tend to infinity in forward time.  This 
statement can be proved by appealing to Theorem~\ref{T:SUC}.    

It follows from Theorem~\ref{T:nlinearization} that if $X_0$ is an
equilibrium\index{equilibrium} and one eigenvalue of $(df)_{X_0}$ has positive 
real part, then almost all solutions near the equilibrium $X_0$ will leave 
small neighborhoods of that equilibrium in forward time.  Thus, in this case 
the equilibrium is not asymptotically stable.

Note that if $(df)_{X_0}$ has an eigenvalue with positive real part and an
eigenvalue with negative real part, then most solutions with initial
conditions near $X_0$ will leave small neighborhoods of $X_0$ in both forward
and backward times.  Such equilibria are called {\em saddles\/}.\index{saddle}

Equilibria are called {\em sources\/}\index{source} when all the eigenvalues 
of the corresponding Jacobian have positive real parts and 
{\em sinks\/}\index{sink} when all the eigenvalues of the corresponding 
Jacobian have negative real parts.



\EXER

\includeexercises





\end{document}
